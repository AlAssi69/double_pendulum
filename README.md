# ğŸ¯ Double Pendulum Sim

A **MATLAB** simulation of a double pendulum with full nonlinear dynamics, optional LQR control, and an RL-ready environment. Perfect for chaos exploration, control design, or reinforcement learning.

---

## ğŸš€ Quick Start

1. **Open** the project folder in MATLAB.
2. **Run** the main script:
   ```matlab
   main
   ```
3. **Configure** (optional): use the config window to set masses, lengths, initial angles, time span, and whether to use LQR control.
4. **Click Start** and watch:
   - ğŸ¬ Real-time pendulum animation  
   - ğŸ“ˆ State plots (angles, velocities, control)  
   - ğŸ—ºï¸ PoincarÃ© map (phase space)

---

## ğŸ“ Project Structure

```
Double Pendulum/
â”œâ”€â”€ main.m                 # Entry point: GUI â†’ simulation â†’ visualization
â”œâ”€â”€ +Core/                 # Physics & simulation engine
â”‚   â”œâ”€â”€ DoublePendulumModel.m   # EOM, linearization
â”‚   â””â”€â”€ Simulator.m             # Stepping, observer pattern (solver from +Integration)
â”œâ”€â”€ +Integration/          # ODE solvers (pluggable)
â”‚   â”œâ”€â”€ ISolver.m                # Abstract interface
â”‚   â”œâ”€â”€ EulerSolver.m            # Explicit Euler
â”‚   â”œâ”€â”€ RK4Solver.m              # Rungeâ€“Kutta 4
â”‚   â”œâ”€â”€ ODE45Solver.m            # MATLAB ode45
â”‚   â””â”€â”€ SolverFactory.m          # getSolver("euler"|"rk4"|"ode45")
â”œâ”€â”€ +Control/              # Controllers
â”‚   â”œâ”€â”€ IController.m           # Abstract interface
â”‚   â”œâ”€â”€ NullController.m        # No control (free swing)
â”‚   â”œâ”€â”€ LQRController.m         # LQR around upright
â”‚   â””â”€â”€ RLPolicyController.m    # Wrapper for RL agent actions
â”œâ”€â”€ +Env/                  # RL environment
â”‚   â””â”€â”€ DoublePendulumEnv.m     # reset/step API, reward, bounds
â”œâ”€â”€ +Vis/                  # Visualization
â”‚   â”œâ”€â”€ VisualizerManager.m     # Coordinates all visualizers
â”‚   â”œâ”€â”€ PendulumAnimator.m      # 2D animation
â”‚   â”œâ”€â”€ StatePlotter.m          # Time-series plots
â”‚   â””â”€â”€ PoincareMap.m           # Phase-space plot
â”œâ”€â”€ +UI/                   # User interface
â”‚   â””â”€â”€ ConfigWindow.m          # Config GUI (uifigure)
â””â”€â”€ +Utils/                # Helpers
    â”œâ”€â”€ ConfigLoader.m          # Default config
    â””â”€â”€ normalizeAngle.m       # Angle normalization
```

| Folder | Role |
|--------|------|
| **+Core** | Physics model (Eulerâ€“Lagrange), simulator (solver from +Integration). |
| **+Integration** | Pluggable ODE solvers: Euler, RK4, ode45; switch via `SolverType`. |
| **+Control** | Null, LQR, or RL policy; all implement `computeControl(t, state)`. |
| **+Env** | RL interface: `reset()`, `step(action)`, reward and clipping. |
| **+Vis** | Animation, state plots, PoincarÃ© map; attached to simulator. |
| **+UI** | Config window for parameters and initial conditions. |
| **+Utils** | Config loading, angle utils. |

---

## âš™ï¸ What You Can Do

- **Free swing** (no control): see chaotic motion and PoincarÃ© maps.  
- **LQR control**: stabilize around the upright equilibrium (toggle in config).  
- **RL training**: use `Env.DoublePendulumEnv` with `reset`/`step` and plug into the MATLAB RL Toolbox or your own agent.

---

## ğŸ”¬ Physics Summary

- **State:** \(x = [\theta_1,\, \theta_2,\, \dot{\theta}_1,\, \dot{\theta}_2]^T\) (rad, rad/s).  
- **Control:** Single torque \(u\) at the shoulder; second joint is unactuated.  
- **Dynamics:** Full nonlinear equations from the Lagrangian; optional damping. No small-angle approximation.

---

## ğŸ¤– Using the RL Environment

`Env.DoublePendulumEnv` provides a standard `reset` / `step` API:

- **Observation:** 4D state vector \(x\).  
- **Action:** Scalar torque, clipped to `[-MaxTorque, MaxTorque]` (default 10 NÂ·m).  
- **Step:** `[next_state, reward, done, info] = env.step(action)` (fixed step, default 0.02 s).  
- **Reset:** `[state, info] = env.reset()` or `env.reset(initial_state)`.

**Default reward:** \(r = -(x - x_{\text{goal}})^T Q (x - x_{\text{goal}}) - R\,u^2\) with goal upright `[0; 0; 0; 0]`. Tune via `Q`, `R`, `GoalState`, `MaxTorque`, `MaxSteps`.

**Minimal loop (no GUI):**

```matlab
model = Core.DoublePendulumModel(struct('m1',1,'m2',1,'L1',1,'L2',1,'g',9.81));
env = Env.DoublePendulumEnv(model, struct('MaxTorque', 10, 'MaxSteps', 500));
[state, info] = env.reset();
for k = 1:500
    u = 0;  % or u = your_policy(state);
    [state, reward, done, info] = env.step(u);
    if done, break; end
end
```

You can wrap this env in the MATLAB Reinforcement Learning Toolbox (e.g. `rlFunctionEnv` or a custom `rl.env.MATLABEnvironment` subclass).

---

## ğŸ“‹ Requirements

- **MATLAB** R2023b+ (R2020b+ for UI; R2023b+ recommended).  
- No extra toolboxes required for basic simulation; RL Toolbox only if you use it for training.

---

## ğŸ“„ License

See [LICENSE](LICENSE). For more design and math details, see [Docs.md](Docs.md).
